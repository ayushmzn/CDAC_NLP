{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5007a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1da171b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "para = \"\"\"Every part of an essay is important, but the first paragraph is vital.\n",
    "This is the first chance you have to impress – or depress – an examiner, and first impressions are often decisive.\n",
    "You might therefore try to write an eye-catching first sentence.\n",
    "(‘Start with an earthquake and work up to a climax,’ counselled the film-maker Cecil B. De Mille.)\n",
    "More important is that you demonstrate your understanding of the question set. \n",
    "Here you give your carefully thought out definitions of the key terms, \n",
    "and here you establish the relevant time-frame and issues – in other words, \n",
    "the parameters of the question. Also, you divide the overall question into more manageable sub-divisions,\n",
    "or smaller questions, on each of which you will subsequently write a paragraph. \n",
    "You formulate an argument, or perhaps voice alternative lines of argument, \n",
    "that you will substantiate later in the essay. Hence the first paragraph – \n",
    "or perhaps you might spread this opening section over two paragraphs – is the key to a good essay.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6f2b809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 - Every part of an essay is important, but the first paragraph is vital.\n",
      "2 - This is the first chance you have to impress – or depress – an examiner, and first impressions are often decisive.\n",
      "3 - You might therefore try to write an eye-catching first sentence.\n",
      "4 - (‘Start with an earthquake and work up to a climax,’ counselled the film-maker Cecil B.\n",
      "5 - De Mille.)\n",
      "6 - More important is that you demonstrate your understanding of the question set.\n",
      "7 - Here you give your carefully thought out definitions of the key terms, \n",
      "and here you establish the relevant time-frame and issues – in other words, \n",
      "the parameters of the question.\n",
      "8 - Also, you divide the overall question into more manageable sub-divisions,\n",
      "or smaller questions, on each of which you will subsequently write a paragraph.\n",
      "9 - You formulate an argument, or perhaps voice alternative lines of argument, \n",
      "that you will substantiate later in the essay.\n",
      "10 - Hence the first paragraph – \n",
      "or perhaps you might spread this opening section over two paragraphs – is the key to a good essay.\n"
     ]
    }
   ],
   "source": [
    "sentences = nltk.sent_tokenize(para)\n",
    "f=0\n",
    "for i in sentences:\n",
    "    f+=1\n",
    "    print(f, '-',i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a072c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "every part essay important  first paragraph vital \n",
      "first chance impress   depress   examiner  first impression often decisive \n",
      "might therefore try write eye catching first sentence \n",
      "  start earthquake work climax   counselled film maker cecil b \n",
      "de mille  \n",
      "important demonstrate understanding question set \n",
      "give carefully thought definition key term   establish relevant time frame issue   word   parameter question \n",
      "also  divide overall question manageable sub division  smaller question  subsequently write paragraph \n",
      "formulate argument  perhaps voice alternative line argument   substantiate later essay \n",
      "hence first paragraph    perhaps might spread opening section two paragraph   key good essay \n"
     ]
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "filtered_sentences = []\n",
    "for i in range(len(sentences)):\n",
    "    words = re.sub('[^a-zA-Z]', ' ', sentences[i])     # replacing everything excepting a-z and A-Z with space\n",
    "    words = words.lower()                              # lowercase\n",
    "    words = words.split(' ')                           # splitting on the basis of spaces\n",
    "    words = [lemmatizer.lemmatize(w) for w in words if w not in stopwords.words('english')]\n",
    "    words = ' '.join(words)\n",
    "    filtered_sentences.append(words)\n",
    "for j in filtered_sentences:\n",
    "    print(j)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "47abfd33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
       "        0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "        0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "        0, 2, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "        0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "        0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "        0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
       "        0, 1, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1,\n",
       "        0, 0, 0, 2, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 1],\n",
       "       [0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "        0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 2,\n",
       "        0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "        0, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer   # it is used to converting text into vectors\n",
    "cv = CountVectorizer()\n",
    "x = cv.fit_transform(filtered_sentences).toarray()\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c83664a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
